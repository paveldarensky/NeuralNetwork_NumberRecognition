{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":803},"id":"Ws_W1JksicsE","executionInfo":{"status":"ok","timestamp":1723714490969,"user_tz":-420,"elapsed":1500,"user":{"displayName":"Павел Даренский","userId":"06829135551534851108"}},"outputId":"5636cf60-7448-4a12-9cac-098503ea6cb9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training examples: 100\n","Each image is of size: (64, 64, 1)\n","train_x_orig shape: (100, 64, 64)\n","train_y shape: (10, 100)\n","train_x's shape: (4096, 100)\n","Модель загружена из файла.\n","Number of testing examples: 1\n","test_x_orig shape: (1, 64, 64)\n","test_y shape: 1\n","test_x's shape: (4096, 1)\n","prediction:\n","[[1.45068841e-03]\n"," [1.01371455e-03]\n"," [1.72340023e-03]\n"," [9.86503230e-01]\n"," [5.50459618e-04]\n"," [2.55275285e-03]\n"," [8.78838488e-04]\n"," [7.26827647e-05]\n"," [4.66820654e-03]\n"," [5.86026668e-04]]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["# @title NeuralNetwork: \"0/1/2/3/4/5/6/7/8/9 - 28x28 (old), 64x64 (new), can any size\"\n","\n","#********************************************** NETWORK **********************************************\n","#********************************************** NETWORK **********************************************\n","#********************************************** NETWORK **********************************************\n","import numpy as np\n","\n","\n","def initialize_parameters_deep(layer_dims):\n","    np.random.seed(1)\n","    parameters = {}\n","    L = len(layer_dims)\n","\n","    for l in range(1, L):\n","        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - 1])/np.sqrt(layer_dims[l-1])\n","        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n","\n","        assert (parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n","        assert (parameters['b' + str(l)].shape == (layer_dims[l], 1))\n","\n","    return parameters\n","\n","\n","def linear_forward(A, W, b):\n","    Z = W.dot(A) + b\n","\n","    assert (Z.shape == (W.shape[0], A.shape[1]))\n","    cache = (A, W, b)\n","\n","    return Z, cache\n","\n","\n","def relu(Z):\n","    A = np.maximum(0,Z)\n","    assert(A.shape == Z.shape)\n","    cache = Z\n","    return A, cache\n","\n","\n","def linear(Z):\n","    cache = Z\n","    return Z, cache\n","\n","\n","def sigmoid(Z):\n","    A = 1/(1 + np.exp(-Z))\n","    cache = Z\n","    return A, cache\n","\n","\n","def softmax(Z):\n","  expZ = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n","  A = expZ / np.sum(expZ, axis=0, keepdims=True)\n","  cache = Z\n","  return A, cache\n","\n","\n","def linear_activation_forward(A_prev, W, b, activation):\n","\n","    Z, linear_cache = linear_forward(A_prev, W, b)\n","    if activation == \"relu\":\n","        A, activation_cache = relu(Z)\n","    elif activation == \"linear\":\n","        A, activation_cache = linear(Z)\n","    elif activation == \"sigmoid\":\n","        A, activation_cache = sigmoid(Z)\n","    elif activation == \"softmax\":\n","        A, activation_cache = softmax(Z)\n","\n","    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n","    cache = (linear_cache, activation_cache)\n","\n","    return A, cache\n","\n","\n","def L_model_forward(X, parameters):\n","    caches = []\n","    A = X\n","    L = len(parameters) // 2\n","\n","    for l in range(1, L):\n","        A_prev = A\n","        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"relu\")\n","        caches.append(cache)\n","\n","    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"softmax\")\n","    caches.append(cache)\n","\n","    assert (AL.shape == (parameters['W' + str(L)].shape[0], X.shape[1]))\n","\n","    return AL, caches\n","\n","\n","# Mean Square Error\n","def Mean_Square_Error(AL, Y, parameters, lambd):\n","    m = Y.shape[1]\n","    cost_mse = (1 / m) * np.sum((AL - Y) ** 2)\n","\n","    L2_regularization_cost = 0\n","    L = len(parameters) // 2\n","    for l in range(1, L + 1):\n","        L2_regularization_cost += (1 / m) * (lambd / 2) * np.sum(np.square(parameters['W' + str(l)]))\n","\n","    cost = cost_mse + L2_regularization_cost\n","    cost = np.squeeze(cost)\n","    assert (cost.shape == ())\n","\n","    return cost\n","\n","\n","# Binary Cross Entropy\n","def Binary_Cross_Entropy(AL, Y, parameters, lambd):\n","    m = Y.shape[1]\n","\n","    eps = 1e-10\n","    BCE_cost = (-1/m) * (np.dot(Y, np.log(AL + eps).T) + np.dot((1 - Y), np.log(1 - AL + eps).T))\n","\n","    L2_regularization_cost = 0\n","    L = len(parameters) // 2\n","    for l in range(1, L + 1):\n","        L2_regularization_cost += (1 / m) * (lambd / 2) * np.sum(np.square(parameters['W' + str(l)]))\n","\n","    cost = BCE_cost + L2_regularization_cost\n","    print(cost.shape)\n","    cost = np.squeeze(cost)\n","    assert (cost.shape == ())\n","\n","    return cost\n","\n","\n","# Cross Entropy Loss\n","def Cross_Entropy_Loss(AL, Y, parameters, lambd):\n","    eps = 1e-10\n","    m = Y.shape[1]\n","    cross_entropy_cost = (-1 / m) * np.sum(Y * np.log(AL + eps))\n","\n","    L2_regularization_cost = 0\n","    L = len(parameters) // 2\n","    for l in range(1, L + 1):\n","        L2_regularization_cost += (1 / m) * (lambd / 2) * np.sum(np.square(parameters['W' + str(l)]))\n","\n","    cost = cross_entropy_cost + L2_regularization_cost\n","    cost = np.squeeze(cost)\n","    assert (cost.shape == ())\n","\n","    return cost\n","\n","\n","def compute_cost(AL, Y, parameters, lambd, function):\n","    if function == \"MSE\":\n","        cost = Mean_Square_Error(AL, Y, parameters, lambd)\n","    elif function == \"BCE\":\n","        cost = Binary_Cross_Entropy(AL, Y, parameters, lambd)\n","    elif function == \"CEL\":\n","        cost = Cross_Entropy_Loss(AL, Y, parameters, lambd)\n","\n","    return cost\n","\n","\n","def linear_backward(dZ, cache):\n","    A_prev, W, b = cache\n","    m = A_prev.shape[1]\n","\n","    dW = (1/m)*np.dot(dZ, A_prev.T)\n","    db = (1/m)*np.sum(dZ, axis=1, keepdims=True)\n","    dA_prev = np.dot(W.T, dZ)\n","\n","    assert (dA_prev.shape == A_prev.shape)\n","    assert (dW.shape == W.shape)\n","    assert (db.shape == b.shape)\n","\n","    return dA_prev, dW, db\n","\n","\n","def relu_backward(dA, activation_cache):\n","    Z = activation_cache\n","    dZ = np.array(dA, copy=True)\n","\n","    dZ[Z <= 0] = 0\n","    assert (dZ.shape == Z.shape)\n","\n","    return dZ\n","\n","\n","def sigmoid_backward(dA, activation_cache):\n","    Z = activation_cache\n","    s = 1/(1 + np.exp(-Z))\n","\n","    dZ = dA*s*(1-s)\n","    assert (dZ.shape == Z.shape)\n","\n","    return dZ\n","\n","\n","def softmax_backward(dA, activation_cache):\n","    # Z = activation_cache\n","    # s = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n","    # s = s / np.sum(s, axis=0, keepdims=True)\n","    # dZ = dA - s\n","    # dZ = dA\n","    # assert (dZ.shape == Z.shape)\n","\n","    return dA\n","\n","\n","def linear_activation_backward(dA, cache, activation):\n","    linear_cache, activation_cache = cache\n","\n","    if activation == \"relu\":\n","        dZ = relu_backward(dA, activation_cache)\n","    elif activation == \"linear\":\n","        dZ = dA\n","    elif activation == \"sigmoid\":\n","        dZ = sigmoid_backward(dA, activation_cache)\n","    elif activation == \"softmax\":\n","        dZ = softmax_backward(dA, activation_cache)\n","\n","    dA_prev, dW, db = linear_backward(dZ, linear_cache)\n","\n","    return dA_prev, dW, db\n","\n","\n","def L_model_backward(AL, Y, caches):\n","    grads = {}\n","    L = len(caches)\n","    m = AL.shape[1]\n","    Y = Y.reshape(AL.shape)\n","\n","    dAL = AL - Y\n","\n","    current_cache = caches[L-1]\n","    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"softmax\")\n","\n","    for l in reversed(range(L-1)):\n","        current_cache = caches[l]\n","        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache, activation = \"relu\")\n","        grads[\"dA\" + str(l)] = dA_prev_temp\n","        grads[\"dW\" + str(l + 1)] = dW_temp\n","        grads[\"db\" + str(l + 1)] = db_temp\n","\n","    return grads\n","\n","\n","def update_parameters(parameters, grads, learning_rate):\n","\n","    L = len(parameters) // 2\n","\n","    for l in range(L):\n","        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate * grads[\"dW\" + str(l+1)]\n","        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate * grads[\"db\" + str(l+1)]\n","\n","    return parameters\n","\n","\n","\n","\n","\n","#********************************************** GO USE NETWORK **********************************************\n","#********************************************** GO USE NETWORK **********************************************\n","#********************************************** GO USE NETWORK **********************************************\n","\n","\n","\"\"\" Prepare datasets for trainings and testings, functions for training, predictions, save/load model  \"\"\"\n","\n","\n","# TESTING NN - \"0/1/2/3/4/5/6/7/8/9 - 28x28 (old), 64x64 (new), can any size\"\n","from PIL import Image\n","import os\n","import matplotlib.pyplot as plt\n","\n","\n","# PREPARE DATASETS FOR TRAIN\n","def load_training_data(base_folder):\n","    train_folders = [os.path.join(base_folder, f\"train/{i}\") for i in range(10)]\n","\n","    num_px = 64\n","    train_images = []     # train_x\n","    train_labels = []     # train_y\n","\n","\n","    for i in range(10):\n","        for filename in os.listdir(train_folders[i]):\n","            image_path = os.path.join(train_folders[i], filename)\n","            image = Image.open(image_path).convert(\"L\").resize([num_px, num_px], Image.LANCZOS)\n","            image = np.array(image)\n","            # Convert grayscale to black and white\n","            image[image < 128] = 0\n","            image[image >= 128] = 255\n","            train_images.append(image)\n","            train_labels.append(i)\n","\n","\n","    train_set_x_orig = np.array(train_images)\n","    train_set_y_orig = np.array(train_labels).reshape(1, -1)\n","\n","    train_set_y_orig = np.eye(10)[train_set_y_orig.flatten()].T\n","\n","    classes = np.array([str(i) for i in range(10)])\n","\n","\n","\n","\n","    m_train = train_set_x_orig.shape[0]\n","\n","    print (\"Number of training examples: \" + str(m_train))\n","    print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 1)\")\n","    print (\"train_x_orig shape: \" + str(train_set_x_orig.shape))\n","    print (\"train_y shape: \" + str(train_set_y_orig.shape))\n","\n","    # Reshape the training and test examples\n","    train_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n","\n","    # Standardize data to have feature values between 0 and 1.\n","    train_x = train_x_flatten/255\n","\n","    print (\"train_x's shape: \" + str(train_x.shape))\n","\n","    return train_x, train_set_y_orig, classes\n","\n","\n","\n","# PREPARE DATASETS FOR TEST\n","# in the future def Take_testing_data_from Draw_App()\n","def load_testing_data(base_folder):\n","    test_folder = os.path.join(base_folder, \"test\")\n","\n","    num_px = 64\n","    test_image = []     # test_x\n","\n","    for filename in os.listdir(test_folder):\n","        image_path = os.path.join(test_folder, filename)\n","        image = Image.open(image_path).convert(\"L\").resize([num_px, num_px], Image.LANCZOS)\n","        image = np.array(image)\n","        # Convert grayscale to black and white\n","        image[image < 128] = 0\n","        image[image >= 128] = 255\n","        test_image.append(image)\n","\n","    test_set_x_orig = np.array(test_image)\n","\n","\n","\n","    m_test = test_set_x_orig.shape[0]\n","\n","    print (\"Number of testing examples: \" + str(m_test))\n","    print (\"test_x_orig shape: \" + str(test_set_x_orig.shape))\n","    print (\"test_y shape: 1\")\n","\n","    # Reshape the training and test examples\n","    test_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T     # The \"-1\" makes reshape flatten the remaining dimensions\n","\n","    # Standardize data to have feature values between 0 and 1.\n","    test_x = test_x_flatten/255\n","\n","    print (\"test_x's shape: \" + str(test_x.shape))\n","\n","    return test_x\n","\n","\n","\n","\n","\n","\n","# TRAINING\n","def training(model, X, Y, learning_rate, num_epochs, batch_size, loss_function, lambd, step__output__cost, flag__output):\n","  parameters = initialize_parameters_deep(model)\n","  m = X.shape[1]\n","\n","  for i in range(num_epochs):\n","    # mix data\n","    permutation = np.random.permutation(m) # mix indexes\n","    X_shuffled = X[:, permutation]\n","    Y_shuffled = Y[:, permutation]\n","\n","    # train by batch\n","    for start in range(0, m, batch_size):\n","      end = min(start + batch_size, m)\n","      X_batch = X_shuffled[:, start:end]\n","      Y_batch = Y_shuffled[:, start:end]\n","\n","      AL, caches = L_model_forward(X_batch, parameters)\n","      cost = compute_cost(AL, Y_batch, parameters, lambd, loss_function)\n","      grads = L_model_backward(AL, Y_batch, caches)\n","      parameters = update_parameters(parameters, grads, learning_rate)\n","\n","\n","    if i % step__output__cost == 0 and flag__output:\n","      print(f\"Cost after epoch {i}: {cost}\")\n","\n","  return parameters\n","\n","\n","\n","# PREDICTION\n","def predict(X, parameters):\n","    probas, caches = L_model_forward(X, parameters)\n","\n","    print(\"prediction:\")\n","    print(probas)\n","\n","    prediction = np.argmax(probas, axis=0)\n","    max_prob = np.max(probas, axis=0)\n","    percent = max_prob[0] * 100\n","\n","    num_px = 64\n","    image = X[:, 0].reshape((num_px, num_px))\n","\n","    # DRAW IMAGE\n","    plt.figure()\n","    plt.imshow(image, cmap='gray')\n","    plt.title(f\"Prediction: {prediction[0]}, {percent:.2f}%\")\n","    plt.axis('off')\n","    plt.show()\n","    # DRAW IMAGE\n","\n","\n","\n","\n","\n","\n","\n","\n","#********************************************** START MODEL **********************************************\n","import pickle\n","import os\n","\n","\n","def save_parameters(parameters, filepath):\n","  with open(filepath, 'wb') as file:\n","    pickle.dump(parameters, file)\n","\n","\n","def load_parameters(filepath):\n","  with open(filepath, 'rb') as file:\n","    return pickle.load(file)\n","\n","\n","def main():\n","  save_trained_parameters_file_path = '/content/drive/MyDrive/NeuralNetworks/NN_Numbers_App/model.pkl'\n","\n","  datasets_folder = \"/content/drive/MyDrive/NeuralNetworks/NN_Numbers_App/DatasetsNumbers_64x64\"\n","\n","  # LOAD TRAINING DATA\n","  train_x, train_y, classes = load_training_data(datasets_folder)\n","\n","\n","\n","  # HYPERPARAMETERS\n","  input_neurons = 4096\n","  output_neurons = 10\n","  model = [input_neurons, 1024, output_neurons]\n","  learning_rate = 0.067\n","  num_epochs = 100\n","  batch_size = 32\n","  loss_function = \"CEL\"\n","  lambd = 0\n","  step__output__cost = int(num_epochs / 10)\n","  flag__output = True\n","\n","\n","\n","  if os.path.exists(save_trained_parameters_file_path):\n","    trained_parameters = load_parameters(save_trained_parameters_file_path)\n","    print(\"Модель загружена из файла.\")\n","  else:\n","    # GO TRAIN PARAMETERS\n","    trained_parameters = training(model, train_x, train_y, learning_rate, num_epochs, batch_size, loss_function, lambd, step__output__cost, flag__output)\n","    save_parameters(trained_parameters, save_trained_parameters_file_path)\n","    print(\"Модель обучена и сохранена в файл.\")\n","\n","\n","  # PREPARE TEST\n","  test_x = load_testing_data(datasets_folder)\n","\n","  # GO PREDICT\n","  predict(test_x, trained_parameters)\n","\n","\n","main()"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[{"file_id":"1Arl3nu0jlfV4oJCrnLcdu5lzuX7zAh1i","timestamp":1723693905186},{"file_id":"1T3p36TqK_apvDwpct4MTz60qfxq7PyXH","timestamp":1722828193968}],"mount_file_id":"1ZHL4rE6V-sAEdGnbDc9JTf-grgN7AXrx","authorship_tag":"ABX9TyNfpEgcu9gUUDlwlQPrb7H6"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
